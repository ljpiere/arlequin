version: "3.9"

x-hadoop-env: &hadoop-common
  CORE_CONF_fs_defaultFS: "hdfs://namenode:9000"
  HDFS_CONF_dfs_replication: "3"

networks:
  backend:

volumes:
  nn-data:
  dn1-data:
  dn2-data:
  dn3-data:

services:
  ################
  #  HDFS LAYER  #
  ################

  namenode:
    image: apache/hadoop:3.4.1
    container_name: namenode
    networks: [backend]
    ports:
      - "9870:9870"   # NameNode UI
      - "9000:9000"   # RPC
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=3
      - CLUSTER_NAME=mlops-demo
    volumes:
      - nn-data:/hadoop/dfs/name
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9870"]
      interval: 30s
      timeout: 10s
      retries: 5

  datanode1:
    image: apache/hadoop:3.4.1
    container_name: datanode1
    networks: [backend]
    depends_on: [namenode]
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=3
    volumes:
      - dn1-data:/hadoop/dfs/data

  datanode2:
    image: apache/hadoop:3.4.1
    container_name: datanode2
    networks: [backend]
    depends_on: [namenode]
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=3
    volumes:
      - dn2-data:/hadoop/dfs/data

  datanode3:
    image: apache/hadoop:3.4.1
    container_name: datanode3
    networks: [backend]
    depends_on: [namenode]
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=3
    volumes:
      - dn3-data:/hadoop/dfs/data

  ################
  #  SPARK LAYER #
  ################

  spark-master:
    image: bitnami/spark:3.5.6
    container_name: spark-master
    networks: [backend]
    ports:
      - "8080:8080"   # Spark Master UI
      - "7077:7077"   # Spark RPC
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    depends_on: [namenode]

  spark-worker-1:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-1
    networks: [backend]
    ports:
      - "8081:8081"   # Worker 1 UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on: [spark-master]

  spark-worker-2:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-2
    networks: [backend]
    ports:
      - "8082:8081"   # Worker 2 UI (mapped al 8081 interno)
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on: [spark-master]

  spark-worker-3:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-3
    networks: [backend]
    ports:
      - "8083:8081"   # Worker 3 UI (mapped al 8081 interno)
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on: [spark-master]
