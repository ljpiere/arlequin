version: "3.9"

x-hadoop-env: &hadoop-common
  CORE_CONF_fs_defaultFS: "hdfs://namenode:9000"
  HDFS_CONF_dfs_replication: "3"

networks:
  backend:

volumes:
  nn-data:
  dn1-data:
  dn2-data:
  dn3-data:

services:
  ################
  #  HDFS LAYER  #
  ################

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    networks:
      - backend
    ports:
      - "9870:9870"   # NameNode UI
      - "9000:9000"   # HDFS RPC
    environment:
      - CLUSTER_NAME=mlops-demo
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_dfs_replication=3
      - CORE_CONF_dfs_namenode_http_address=0.0.0.0:9870
    volumes:
      - nn-data:/hadoop/dfs/name

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    networks:
      - backend
    depends_on:
      - namenode
    environment:
      - CLUSTER_NAME=mlops-demo
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_dfs_replication=3
    volumes:
      - dn1-data:/hadoop/dfs/data

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    networks:
      - backend
    depends_on:
      - namenode
    environment:
      - CLUSTER_NAME=mlops-demo
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_dfs_replication=3
    volumes:
      - dn2-data:/hadoop/dfs/data

  datanode3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode3
    networks:
      - backend
    depends_on:
      - namenode
    environment:
      - CLUSTER_NAME=mlops-demo
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_dfs_replication=3
    volumes:
      - dn3-data:/hadoop/dfs/data

  ################
  #  SPARK LAYER #
  ################

  spark-master:
    image: bitnami/spark:3.5.6
    container_name: spark-master
    networks: [backend]
    ports:
      - "8080:8080"   # Spark Master UI
      - "7077:7077"   # Spark RPC
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    depends_on: [namenode]

  spark-worker-1:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-1
    networks: [backend]
    ports:
      - "8081:8081"   # Worker 1 UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on: [spark-master]

  spark-worker-2:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-2
    networks: [backend]
    ports:
      - "8082:8081"   # Worker 2 UI (mapped al 8081 interno)
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on: [spark-master]

  spark-worker-3:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-3
    networks: [backend]
    ports:
      - "8083:8081"   # Worker 3 UI (mapped al 8081 interno)
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on: [spark-master]
