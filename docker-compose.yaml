version: "3.9"

x-hadoop-env: &hadoop-common
  CORE_CONF_fs_defaultFS: "hdfs://namenode:9000"
  HDFS_CONF_dfs_replication: "3"

networks:
  backend:

volumes:
  nn-data:
  dn1-data:
  dn2-data:
  dn3-data:

services:
  ################
  #  HDFS LAYER  #
  ################

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    networks:
      - backend
    ports:
      - "9870:9870"   # NameNode UI
      - "9000:9000"   # HDFS RPC
    environment:
      - CLUSTER_NAME=mlops-demo
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_dfs_replication=3
      - CORE_CONF_dfs_namenode_http_address=0.0.0.0:9870
    volumes:
      - nn-data:/hadoop/dfs/name

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    networks:
      - backend
    depends_on:
      - namenode
    environment:
      - CLUSTER_NAME=mlops-demo
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_dfs_replication=3
    volumes:
      - dn1-data:/hadoop/dfs/data

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    networks:
      - backend
    depends_on:
      - namenode
    environment:
      - CLUSTER_NAME=mlops-demo
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_dfs_replication=3
    volumes:
      - dn2-data:/hadoop/dfs/data

  datanode3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode3
    networks:
      - backend
    depends_on:
      - namenode
    environment:
      - CLUSTER_NAME=mlops-demo
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - CORE_CONF_dfs_replication=3
    volumes:
      - dn3-data:/hadoop/dfs/data

  ################
  #  SPARK LAYER #
  ################

  spark-master:
    image: bitnami/spark:3.5.6
    container_name: spark-master
    networks: [backend]
    ports:
      - "8080:8080"   # Spark Master UI
      - "7077:7077"   # Spark RPC
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    depends_on: [namenode]

  spark-worker-1:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-1
    networks: [backend]
    ports:
      - "8081:8081"   # Worker 1 UI
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on: [spark-master]

  spark-worker-2:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-2
    networks: [backend]
    ports:
      - "8082:8081"   # Worker 2 UI (mapped al 8081 interno)
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on: [spark-master]

  spark-worker-3:
    image: bitnami/spark:3.5.6
    container_name: spark-worker-3
    networks: [backend]
    ports:
      - "8083:8081"   # Worker 3 UI (mapped al 8081 interno)
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on: [spark-master]

##################
#  KAFKA LAYER   #
##################
zookeeper:
  image: bitnami/zookeeper:3.9
  container_name: zookeeper
  networks: [backend]
  environment:
    - ALLOW_ANONYMOUS_LOGIN=yes
  ports:
    - "2181:2181"

kafka:
  image: bitnami/kafka:3.7
  container_name: kafka
  networks: [backend]
  depends_on: [zookeeper]
  ports:
    - "9092:9092"          # clientes locales
    - "9093:9093"          # interna cluster
  environment:
    - KAFKA_BROKER_ID=1
    - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
    - KAFKA_CFG_LISTENERS=INTERNAL://kafka:9093,EXTERNAL://0.0.0.0:9092
    - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9093,EXTERNAL://localhost:9092
    - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
    - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
    - ALLOW_PLAINTEXT_LISTENER=yes
    # crea los tres topics al arrancar
    - KAFKA_CREATE_TOPICS=inference_raw:3:3,metrics:3:3,alerts:3:3
