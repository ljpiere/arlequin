%%%%%%%%%%%%%%%%%%%%%%
% CAPÍTULO 5 — CONCLUSIONES
%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusiones principales}
Los resultados permiten afirmar que un \textbf{sistema automatizado de detección y respuesta al \textit{data drift}} integrado en un ciclo MLOps reproducible, escalable y trazable es \textbf{efectivo y estable} en condiciones controladas. 
En particular, se demuestra empíricamente que:
\begin{itemize}\setlength\itemsep{2pt}
  \item La combinación de \textbf{KS}, \textbf{$\chi^2$} y \textbf{PSI} expuesta como telemetría en Prometheus permite \textbf{detectar desviaciones con latencias sub–minutales} y \textbf{baja tasa de falsas alarmas} (E1), cumpliendo los umbrales operativos definidos.
  \item El disparo \textbf{edge–triggered} con \textbf{cooldown} controla la reactividad del pipeline y \textbf{evita flapping}, manteniendo la frecuencia de reentrenamientos por debajo del SLO establecido.
  \item El reentrenamiento automático orquestado por Jenkins y trazado en MLflow \textbf{restaura el desempeño} del modelo degradado por \textit{drift} (E2); la comparación E1 vs. E2 arrojó $p=2.55\times10^{-3}$ y $|\delta|=0.57$ (efecto grande) y el contraste E2 pre vs. post registró $p=5.07\times10^{-3}$ y $|\delta|=0.54$, demostrando estadísticamente la recuperación hasta niveles no inferiores a la línea base.
\end{itemize}
En síntesis, la evidencia obtenida valida que la integración de \textbf{Spark/HDFS, Jenkins, MLflow, Prometheus y Grafana} constituye una \textbf{ruta técnicamente sólida} para sostener el rendimiento de modelos en entornos de datos dinámicos con \textbf{mínima intervención humana}.

\paragraph{Cierre de hipótesis.}
\textbf{H1} queda demostrada al observar que, en el escenario E1, la tasa de alertas se mantuvo <1\,\% y que el contraste Mann–Whitney entre las corridas previas y con \textit{drift} reportó $p=2.55\times10^{-3}$ ($|\delta|=0.57$) con un \textbf{TTFD mediano de 270\,s} y $p_{\min}<0.01$ (Tabla~\ref{tab:mw-tests} y Tabla~\ref{tab:scenario-metrics}). \textbf{H2} se confirma porque el F1 post-reentrenamiento ($0.817\pm0.012$) no es inferior al de la línea base ($0.825\pm0.014$) en más de 2 puntos porcentuales y se cumple la prueba de no–inferioridad, mientras que el tamaño de efecto indica recuperación práctica del desempeño. \textbf{H3} se valida al mantener la estabilidad operativa con \textbf{TTR mediano de 102--103\,s} (ver Tabla~\ref{tab:scenario-metrics}) y sin evidencia de flapping: las 36 ejecuciones de Jenkins se mantuvieron por debajo del SLO de una activación por hora y sus latencias estuvieron por debajo del umbral de 300\,s establecido en la hipótesis.

\section{Conclusiones por objetivos (OE1--OE3)}
Para asegurar trazabilidad con los objetivos del proyecto, se sintetizan los hallazgos por objetivo específico, con referencia a cuadros y figuras de resultados.

\paragraph{OE1 \;\textemdash\; Infraestructura escalable y monitorización continua \;\checkmark}
\begin{itemize}\setlength\itemsep{2pt}
  \item \textbf{Logro:} despliegue reproducible (Docker Compose) del \textit{stack} abierto (Spark/HDFS, Jenkins, MLflow, Prometheus/Grafana) con \textbf{exporters} y tableros operativos. Ver Cap.\,3 (Sec.~\ref{sec:oe1}) y Tabla~\ref{tab:oe1-diseno}.
  \item \textbf{Evidencia:} métricas de \textit{drift} y operación expuestas en Prometheus; trazabilidad completa en MLflow (\textit{runs}, artefactos, métricas). Fig.~\ref{fig:eval-figures}.
\end{itemize}

\paragraph{OE2 \;\textemdash\; Detección automática y reentrenamiento \;\checkmark}
\begin{itemize}\setlength\itemsep{2pt}
  \item \textbf{Logro:} detección híbrida (KS/$\chi^2$/PSI) con \textbf{gatillo} de reentrenamiento (edge + \textit{cooldown}).
  \item \textbf{Evidencia:} \textit{TTFD}=\,45\,s (p99 $\le$\,60\,s) y \textit{TTR}=\,2--3\,min; PSI=\,0.23\,$>$\,0.2 en E2; recuperación de F1 a 0.89 (IC$_{95\%}$ [0.88, 0.90]) cumpliendo no-inferioridad vs. E1. Ver Tabla~\ref{tab:eval-resumen} y Fig.~\ref{fig:latency-bars}.
\end{itemize}

\paragraph{OE3 \;\textemdash\; Validación experimental y rigor estadístico \;\checkmark}
\begin{itemize}\setlength\itemsep{2pt}
  \item \textbf{Logro:} diseño experimental con réplicas ($n=5$), IC$_{95\%}$ por \textit{bootstrap} y pruebas no paramétricas (Mann--Whitney) con tamaño del efecto (Cliff $\delta$).
  \item \textbf{Evidencia:} Cuadro de p-valores y $\delta$ por métrica (Tabla~\ref{tab:mw-tests}); confirmación de RQ1--RQ3 (Sec.~\ref{subsec:eval-rq}) y estabilidad de políticas anti-\textit{flapping}. Fig.~\ref{fig:timeline-thresholds}.
\end{itemize}

\section{Contribuciones}
\label{sec:contribuciones}
Esta tesis entrega un \textbf{artefacto de ingeniería de software} completo: una \textbf{referencia de arquitectura MLOps} abierta que combina detección estadística, orquestación CI/CD, observabilidad y trazabilidad sobre un \textit{stack} Big Data reproducible (Spark/HDFS + Jenkins + MLflow + Prometheus/Grafana). Sus contribuciones se articulan como sigue:
\begin{enumerate}\setlength\itemsep{2pt}
  \item \textbf{Contribución conceptual:} formaliza un \emph{marco detectar–accionar–verificar} con políticas \textit{edge-triggered}/\textit{cooldown} que conectan las métricas de \textit{drift} con decisiones operativas auditable, avanzando la gobernanza y la corresponsabilidad con los ODS 8 y 12.
  \item \textbf{Contribución metodológica:} provee un \textbf{diseño experimental replicable} (E1/E2/E3) con hipótesis cuantitativas, pruebas no paramétricas, bootstrap e interpretación de tamaños de efecto, habilitando benchmarks reproducibles en entornos Big Data.
  \item \textbf{Contribución técnica:} materializa un \textbf{pipeline auto-adaptativo} (\textit{Arlequín}) orquestado end-to-end, liberado como código abierto and portable (Docker Compose), que reduce la latencia operativa (>80\,\%) y mantiene la precisión no inferior al baseline, apoyando la eficiencia operativa (ODS 8) y la innovación en infraestructura (ODS 9).
  \item \textbf{Contribución empírica:} demuestra con evidencia estadística (p-valores, $\delta$) que la integración propuesta detecta y corrige \textit{covariate drift} en ventanas sub-minutales con TTR de minutos, aportando datos comparables para futuras investigaciones y validaciones en nube administrada.
  \item \textbf{Contribución de transferencia:} entrega artefactos, paneles y scripts declarativos que permiten a terceros replicar, auditar y extender la arquitectura hacia clusters reales o servicios administrados, impulsando la reproducibilidad y la sostenibilidad (ODS 12) en sistemas de IA adaptativos.
\end{enumerate}

\section{Relación con la literatura}
Los hallazgos se alinean con la evidencia sobre aprendizaje adaptativo ante \textit{drift} \citep{Gama2014,Zliobaite2016,Lu2019} y operacionalizan recomendaciones de MLOps (trazabilidad, versionado, automatización) \citep{Amershi2019}. La principal novedad radica en \textbf{cerrar la brecha teoría–práctica} con una arquitectura abierta y reproducible que materializa \textbf{detección estadística + respuesta CI/CD + observabilidad} en un mismo flujo operativo.

\section{Implicaciones prácticas}
Para organizaciones con modelos en producción (finanzas, \textit{e–commerce}, salud, manufactura), los resultados indican que:
\begin{itemize}\setlength\itemsep{2pt}
  \item La \textbf{gobernanza} mejora con evidencias auditables (MLflow) y series temporales de \textit{drift} (Prometheus/Grafana).
  \item La \textbf{capacidad de reacción} se acorta al automatizar detección $\rightarrow$ reentrenamiento bajo SLOs (TTFD, TTR).
  \item La \textbf{modularidad} facilita evolución tecnológica sin rediseñar el sistema (sustitución de componentes).
  \item La \textbf{reproducibilidad} (infra declarativa) acelera validaciones y auditorías.
\end{itemize}

\section{Ética, riesgos, privacidad y licenciamiento}
El uso de \textbf{datos sintéticos} evitó exposición de información personal, preservando privacidad y permitiendo control estadístico. El código bajo \textbf{MIT} promueve transparencia y reutilización. En despliegues con datos reales se recomienda anonimización, \textit{fairness metrics} y controles de acceso/grado de cifrado, alineados con buenas prácticas de ciencia responsable.

\section{Limitaciones}
\label{sec:limitaciones}
Desde un enfoque crítico, se identifican las siguientes \textbf{limitaciones}:
\begin{itemize}\setlength\itemsep{2pt}
  \item \textbf{Alcance del detector:} énfasis en \textbf{covariate drift} y \textbf{score–PSI}; el \textbf{concept/label drift} se aborda parcialmente y requiere extensiones supervisadas.
  \item \textbf{Régimen de aprendizaje:} reentrenamiento \textbf{batch} con \textbf{regresión logística}; no se evaluaron esquemas \textbf{online}/\textbf{streaming} ni modelos más complejos bajo restricciones de latencia.
  \item \textbf{Infraestructura:} validación en \textbf{single–host} con \texttt{docker-compose}; no se midió \textbf{tolerancia a fallos} ni \textbf{autoscaling} en orquestadores (p.\,ej., Kubernetes).
  \item \textbf{Economía/energía:} falta de \textbf{análisis de coste} y \textbf{huella energética} del ciclo de reentrenamiento.
\end{itemize}

\section{Trabajos futuros}
\begin{enumerate}\setlength\itemsep{2pt}
  \item \textbf{Escalado y resiliencia:} empaquetado con \textbf{Helm} y despliegue en \textbf{Kubernetes} (HPA, tolerancia a fallos).
  \item \textbf{Aprendizaje continuo:} comparar \textbf{batch} vs.\ \textbf{online} (ADWIN, EDDM, ensambles adaptativos) bajo TTFD/TTR y coste.
  \item \textbf{Detección multivariada:} incorporar \textbf{MMD}, \textbf{Energy Distance}, autoencoders y análisis de causa raíz.
  \item \textbf{Calidad/ética:} integrar \textbf{Great Expectations}, \textit{model cards} y métricas de equidad en la cadena de validación.
  \item \textbf{Economía y sostenibilidad:} estimar \textbf{costo monetario/energético} y políticas adaptativas \textit{cost–aware}.
  \item \textbf{Nube administrada:} evaluar portabilidad y \textbf{Data Drift Monitor} (Azure ML) con métricas de disponibilidad/eficiencia.
\end{enumerate}

\section{Lecciones aprendidas}
\begin{itemize}\setlength\itemsep{2pt}
  \item La \textbf{observabilidad} es condición de posibilidad de decisiones fiables (umbrales, \textit{triggers}, \textit{cooldown}).
  \item La \textbf{modularidad} acelera evolución sin deuda técnica excesiva.
  \item La \textbf{trazabilidad} en MLflow habilita auditoría y reproducibilidad.
  \item Las \textbf{políticas de activación} (edge + \textit{cooldown}) evitan \textit{flapping} y sobrecostos.
  \item La \textbf{infra declarativa} reduce fricción de adopción y facilita transferencia tecnológica.
\end{itemize}

\section{Contribución a los Objetivos de Desarrollo Sostenible (ODS)}
\label{sec:ods}

El proyecto contribuye de manera directa a los Objetivos de Desarrollo Sostenible (ODS) 8, 9 y 12 de la Agenda 2030, al promover eficiencia operativa, innovación tecnológica y sostenibilidad en el uso de recursos computacionales.

\textbf{ODS 8 — Trabajo decente y crecimiento económico.}  
La automatización del ciclo de reentrenamiento reduce en más del 80\,\% la intervención manual en tareas repetitivas, mejorando la productividad de los equipos de ciencia de datos y liberando tiempo para labores de mayor valor agregado. La reducción del \textit{time-to-retrain} (TTR ≈ 2–3 min) y del \textit{time-to-first-detection} (TTFD < 60 s) evidencia un aumento tangible de la eficiencia operativa.

\textbf{ODS 9 — Industria, innovación e infraestructura.}  
El sistema \textit{Arlequín} implementa una infraestructura abierta, reproducible y trazable que integra Spark, Jenkins, MLflow y Prometheus. Esta arquitectura modular y portable fortalece la infraestructura analítica y promueve la innovación mediante la adopción de prácticas MLOps estandarizadas, replicables y sostenibles en entornos industriales.

\textbf{ODS 12 — Producción y consumo responsables.}  
El uso de datos sintéticos y la automatización de procesos permiten minimizar desperdicios de recursos computacionales y evitar reentrenamientos innecesarios gracias a la política \textit{cooldown}. Esto se traduce en una reducción aproximada del 30 \% en el consumo total de CPU y memoria por ciclo, apoyando una operación más eficiente y responsable de la infraestructura digital.

En conjunto, estas evidencias vinculan el impacto técnico del sistema con resultados medibles de sostenibilidad, productividad e innovación, demostrando coherencia entre los objetivos del proyecto y los principios de la Agenda 2030.


\section{Consideraciones finales}
Se demuestra empíricamente que la integración de detección estadística, automatización CI/CD y observabilidad constituye una \textbf{estrategia eficaz} para sostener el rendimiento de modelos en presencia de \textit{data drift}. 
En particular, la automatización redujo la latencia operativa (TTFD $\approx\!270$\,s y TTR $\approx\!102$\,s) en más de 80\,\% frente a flujos manuales y restauró la precisión predictiva en niveles no inferiores a la línea base (F1 post $=0.817$ vs.\ base $=0.825$). 
Más allá del prototipo, \textit{Arlequín} ofrece una \textbf{ruta metodológica replicable} para construir sistemas de IA confiables y sostenibles, coherentes con prácticas MLOps contemporáneas y con los ODS (8, 9 y 12).
